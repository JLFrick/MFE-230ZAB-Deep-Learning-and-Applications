{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Windows Function\n",
    "\n",
    "### **Inputs:**\n",
    "- `returns`: pandas DataFrame of asset returns with dates as index and assets as columns.\n",
    "- `memory`: window size (number of periods).\n",
    "- `min_period`: minimum periods required to compute a covariance matrix, default is 20.\n",
    "\n",
    "### **Breakdown of Variables:**\n",
    "- `min_periods`: Ensures periods are at least 1 or 20 to avoid division by 0.\n",
    "- `times`: Stores the timestamp of each row of returns.\n",
    "- `assets`: Stores asset names for each column of returns.\n",
    "- `returns`: Converts the DataFrame into a numpy array (for faster computing).\n",
    "- `Sigmas`: A 3D array to store the covariance matrices at each time step (# time step, # assets, # assets).\n",
    "- `Sigmas[0]`: Initializes the first covariance matrix as the outer product of the first return vector.\n",
    "\n",
    "### **Logic + Useful Formulas to Add to PowerPoint:**\n",
    "To compute rolling window covariance matrices over time using recursive updates for both increasing and fixed window sizes:\n",
    "\n",
    "### 1. Initialize\n",
    "Start covariance matrix computed from the first observation:\n",
    "\n",
    "$\\Sigma_{0} = r_{0} r_{0}^{\\top}$\n",
    "\n",
    "### 2. Recursive Updates\n",
    "##### a. Scaling factors adjusted based on the number of observations:\n",
    "- \n",
    "##### b. Before the window reaches full size $(t < \\text{memory})$:\n",
    "- Let $S_t$ be the cumulative sum up to time $t$:\n",
    "\n",
    "  $S_{t} = S_{t-1} + r_{t} r_{t}^{\\top}$\n",
    "\n",
    "- A sample covariance matrix at time $t$ is:\n",
    "\n",
    "  $\\Sigma_{t} = \\frac{1}{t+1} S_{t}$\n",
    "\n",
    "- Update the cumulative covariance with each new observation:\n",
    "\n",
    "  $\\Sigma_{t} = \\left(\\frac{t}{t+1}\\right) \\Sigma_{t-1} + \\frac{1}{t+1} r_{t} r_{t}^{\\top}$\n",
    "\n",
    "- Since $\\Sigma_{t-1} = \\frac{1}{t} S_{t-1}$, adjust for the increasing number of observations.\n",
    "\n",
    "##### c. After the window reaches full size $(t > \\text{memory})$:\n",
    "- Maintain a rolling sum by adding the new observation and subtracting the oldest one:\n",
    "\n",
    "  $S_{t} = S_{t-1} + r_{t} r_{t}^{\\top} - r_{t-\\text{memory}} r_{t-\\text{memory}}^{\\top}$\n",
    "\n",
    "- Sample covariance matrix, keeping the window size fixed at `memory` (e.g., 125 days):\n",
    "\n",
    "  $\\Sigma_{t} = \\frac{1}{\\text{memory}} S_{t}$\n",
    "\n",
    "- Recursive formula combining the two:\n",
    "\n",
    "  $\\Sigma_{t} = \\Sigma_{t-1} + \\frac{1}{\\text{memory}} \\left(r_{t} r_{t}^{\\top} - r_{t-\\text{memory}} r_{t-\\text{memory}}^{\\top}\\right)$\n",
    "\n",
    "#### 3. Return\n",
    "Return a dictionary mapping each timestamp to its corresponding covariance matrix.\n",
    "\n",
    "### **How Scaling Factors are Derived**\n",
    "\n",
    "#### 1. Express $\\Sigma_t$ in Terms of $\\Sigma_{t-1}$\n",
    "\n",
    "First, let's express $S_t$ in terms of $\\Sigma_{t-1}$:\n",
    "\n",
    "$\n",
    "S_t = S_{t-1} + r_t r_t^{\\top} = N_{t-1} \\Sigma_{t-1} + r_t r_t^{\\top}\n",
    "$\n",
    "\n",
    "Since $S_{t-1} = N_{t-1} \\Sigma_{t-1}$.\n",
    "\n",
    "#### 2. Substitute $S_t$ into $\\Sigma_t$\n",
    "\n",
    "$\n",
    "\\Sigma_t = \\frac{1}{N_t} (N_{t-1} \\Sigma_{t-1} + r_t r_t^{\\top})\n",
    "$\n",
    "\n",
    "#### 3. Simplify the Expression\n",
    "\n",
    "Recognize that $N_t = N_{t-1} + 1$, so:\n",
    "\n",
    "$\n",
    "\\Sigma_t = \\left(\\frac{N_{t-1}}{N_t}\\right) \\Sigma_{t-1} + \\left(\\frac{1}{N_t}\\right) r_t r_t^{\\top}\n",
    "$\n",
    "\n",
    "In terms of $\\alpha_{\\text{old}}$ and $\\alpha_{\\text{new}}$:\n",
    "\n",
    "$\n",
    "\\alpha_{\\text{old}} = \\frac{1}{N_{t-1}}, \\quad \\alpha_{\\text{new}} = \\frac{1}{N_t}\n",
    "$\n",
    "\n",
    "#### 4. Thus, the recursive update formula is:\n",
    "\n",
    "$\n",
    "\\Sigma_t = \\left(\\frac{\\alpha_{\\text{old}}}{\\alpha_{\\text{new}}}\\right) \\Sigma_{t-1} + \\alpha_{\\text{new}} r_t r_t^{\\top}\n",
    "$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$\n",
    "\\alpha_{\\text{old}} = \\frac{1}{t+1}, \\quad \\alpha_{\\text{new}} = \\frac{1}{t+2}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(returns, memory, min_periods=20):\n",
    "    min_periods = max(min_periods, 1)\n",
    "\n",
    "    times = returns.index\n",
    "    assets = returns.columns\n",
    "\n",
    "    returns = returns.values\n",
    "\n",
    "    Sigmas = np.zeros((returns.shape[0], returns.shape[1], returns.shape[1]))\n",
    "    Sigmas[0] = np.outer(returns[0], returns[0])\n",
    "\n",
    "    for t in range(1, returns.shape[0]):\n",
    "        alpha_old = 1 / min(t + 1, memory)\n",
    "        alpha_new = 1 / min(t + 2, memory)\n",
    "\n",
    "        if t >= memory:\n",
    "            Sigmas[t] = alpha_new / alpha_old * Sigmas[t - 1] + alpha_new * (\n",
    "                np.outer(returns[t], returns[t])\n",
    "                - np.outer(returns[t - memory], returns[t - memory])\n",
    "            )\n",
    "        else:\n",
    "            Sigmas[t] = alpha_new / alpha_old * Sigmas[t - 1] + alpha_new * (\n",
    "                np.outer(returns[t], returns[t])\n",
    "            )\n",
    "\n",
    "    Sigmas = Sigmas[min_periods - 1 :]\n",
    "    times = times[min_periods - 1 :]\n",
    "\n",
    "    return {\n",
    "        times[t]: pd.DataFrame(Sigmas[t], index=assets, columns=assets)\n",
    "        for t in range(len(times))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ewma_cov(data, halflife, min_periods=0):\n",
    "    \"\"\"\n",
    "    param data: Txn pandas DataFrame of returns\n",
    "    param halflife: float, halflife of the EWMA\n",
    "    \"\"\"\n",
    "\n",
    "    for t, ewma in _general(\n",
    "        data.values,\n",
    "        times=data.index,\n",
    "        halflife=halflife,\n",
    "        fct=lambda x: np.outer(x, x),\n",
    "        min_periods=min_periods,\n",
    "    ):\n",
    "        if not np.isnan(ewma).all():\n",
    "            yield t, pd.DataFrame(index=data.columns, columns=data.columns, data=ewma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iterated_ewma(\n",
    "    returns,\n",
    "    vola_halflife,\n",
    "    cov_halflife,\n",
    "    min_periods_vola=20,\n",
    "    min_periods_cov=20,\n",
    "    mean=False,\n",
    "    mu_halflife1=None,\n",
    "    mu_halflife2=None,\n",
    "    clip_at=None,\n",
    "    nan_to_num=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    param returns: pandas dataframe with returns for each asset\n",
    "    param vola_halflife: half life for volatility\n",
    "    param cov_halflife: half life for covariance\n",
    "    param min_preiods_vola: minimum number of periods to use for volatility\n",
    "    ewma estimate\n",
    "    param min_periods_cov: minimum number of periods to use for covariance\n",
    "    ewma estimate\n",
    "    param mean: whether to estimate mean; if False, assumes zero mean data\n",
    "    param mu_halflife1: half life for the first mean adjustment; if None, it is\n",
    "    set to vola_halflife; only applies if mean=True\n",
    "    param mu_halflife2: half life for the second mean adjustment; if None, it is\n",
    "    set to cov_halflife; only applies if mean=True\n",
    "    param clip_at: winsorizes ewma update at +-clip_at*(current ewma) in ewma;\n",
    "    if None, no winsorization is performed\n",
    "    nan_to_num: if True, replace NaNs in returns with 0.0\n",
    "    \"\"\"\n",
    "    mu_halflife1 = mu_halflife1 or vola_halflife\n",
    "    mu_halflife2 = mu_halflife2 or cov_halflife"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(returns, covariances):\n",
    "    returns_shifted = returns.shift(-1)\n",
    "\n",
    "    MSEs = []\n",
    "    for time, cov in covariances.items():\n",
    "        realized_cov = returns_shifted.loc[time].values.reshape(\n",
    "            -1, 1\n",
    "        ) @ returns_shifted.loc[time].values.reshape(1, -1)\n",
    "        MSEs.append(np.linalg.norm(cov - realized_cov) ** 2)\n",
    "\n",
    "    return pd.Series(MSEs, index=covariances.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_low_rank(returns, Sigmas, means=None):\n",
    "    \"\"\"\n",
    "    Computes the log-likelihoods\n",
    "\n",
    "    param returns: pandas DataFrame of returns\n",
    "    param Sigmas: dictionary of covariance matrices where each covariance matrix\n",
    "                  is a namedtuple with fields \"F\" and \"d\"\n",
    "    param means: pandas DataFrame of means\n",
    "\n",
    "    Note: Sigmas[time] is covariance prediction for returns[time+1]\n",
    "        same for means.loc[time]\n",
    "    \"\"\"\n",
    "    returns = returns.shift(-1)\n",
    "\n",
    "    ll = []\n",
    "    m = np.zeros_like(returns.iloc[0].values).reshape(-1, 1)\n",
    "\n",
    "    times = []\n",
    "\n",
    "    for time, low_rank in Sigmas.items():\n",
    "        # TODO: forming the covariance matrix is bad...\n",
    "        cov = low_rank.F @ (low_rank.F).T + np.diag(low_rank.d)\n",
    "\n",
    "        if not returns.loc[time].isna()[0]:\n",
    "            if means is not None:\n",
    "                m = means.loc[time].values.reshape(-1, 1)\n",
    "            ll.append(\n",
    "                _single_log_likelihood(\n",
    "                    returns.loc[time].values.reshape(-1, 1), cov.values, m\n",
    "                )\n",
    "            )\n",
    "            times.append(time)\n",
    "\n",
    "    return pd.Series(ll, index=times).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    n = len(data)\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, n + 1) / n\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_diagonal(Sigmas, lamda):\n",
    "    \"\"\"\n",
    "    Adds lamda*diag(Sigma) to each covariance (Sigma) matrix in Sigmas\n",
    "\n",
    "    param Sigmas: dictionary of covariance matrices\n",
    "    param lamda: scalar\n",
    "    \"\"\"\n",
    "    for key in Sigmas.keys():\n",
    "        Sigmas[key] = Sigmas[key] + lamda * np.diag(np.diag(Sigmas[key]))\n",
    "\n",
    "    return Sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_row_to_covariance(row, n):\n",
    "    \"\"\"\n",
    "    Convert upper diagonal part of covariance matrix to a covariance matrix\n",
    "    \"\"\"\n",
    "    Sigma = np.zeros((n, n))\n",
    "\n",
    "    # set upper triangular part\n",
    "    upper_mask = np.triu(np.ones((n, n)), k=0).astype(bool)\n",
    "    Sigma[upper_mask] = row\n",
    "\n",
    "    # set lower triangular part\n",
    "    lower_mask = np.tril(np.ones((n, n)), k=0).astype(bool)\n",
    "    Sigma[lower_mask] = Sigma.T[lower_mask]\n",
    "    return Sigma"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
